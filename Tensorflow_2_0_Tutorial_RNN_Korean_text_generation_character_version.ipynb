{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tensorflow 2.0 Tutorial - RNN - Korean text generation - character version.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sun-Joong/aifh/blob/master/Tensorflow_2_0_Tutorial_RNN_Korean_text_generation_character_version.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73P3Yqmxibl6",
        "colab_type": "text"
      },
      "source": [
        "# 구글 텐서플로우 첫걸음\n",
        "## Tensorflow 2.0 Sample Code\n",
        "### RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRFQPw4Oiiv6",
        "colab_type": "text"
      },
      "source": [
        "이 샘플 코드는 Tensorflow 2.0 에서 RNN 을 간단하게 살펴보기 위한 용도로 만들어졌습니다. \n",
        "\n",
        "이 코드는 텐서플로우 공식 홈페이지에 있는 [Text generation using a RNN with eager execution](<https://www.tensorflow.org/tutorials/sequences/text_generation?hl=ko>)의 [colab버전](<https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/sequences/text_generation.ipynb?hl=ko>)을 참조했습니다.\n",
        "\n",
        "이 코드에서는 한국 힙합 노래 가사 11,937 곡의 데이터를 이용해서 새로운 노래 가사를 생성해봅니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYzRS9V1imNj",
        "colab_type": "text"
      },
      "source": [
        "## 초기 환경 세팅"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6MsQfe2iSIY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577
        },
        "outputId": "9ac84e4c-2191-40b6-d578-44f2d23c2da8"
      },
      "source": [
        "# 텐서플로우 2.0 을 설치합니다.\n",
        "!pip install tensorflow-gpu==2.0.0-alpha0\n",
        "\n",
        "# 텐서플로우를 python 에 import 합니다.\n",
        "import tensorflow as tf\n",
        "\n",
        "# 텐서플로우의 버전을 확인해봅니다.\n",
        "print(tf.__version__)\n",
        "\n",
        "# numpy 를 np 라는 이름으로 축약해서 import 합니다.\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==2.0.0-alpha0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/66/32cffad095253219d53f6b6c2a436637bbe45ac4e7be0244557210dc3918/tensorflow_gpu-2.0.0a0-cp36-cp36m-manylinux1_x86_64.whl (332.1MB)\n",
            "\u001b[K     |████████████████████████████████| 332.1MB 61kB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.33.4)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (3.7.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.0.7)\n",
            "Collecting tb-nightly<1.14.0a20190302,>=1.14.0a20190301 (from tensorflow-gpu==2.0.0-alpha0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/51/aa1d756644bf4624c03844115e4ac4058eff77acd786b26315f051a4b195/tb_nightly-1.14.0a20190301-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 35.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.7.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.12.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.2.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.0.9)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.16.3)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.8.0)\n",
            "Collecting tf-estimator-nightly<1.14.0.dev2019030116,>=1.14.0.dev2019030115 (from tensorflow-gpu==2.0.0-alpha0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/82/f16063b4eed210dc2ab057930ac1da4fbe1e91b7b051a6c8370b401e6ae7/tf_estimator_nightly-1.14.0.dev2019030115-py2.py3-none-any.whl (411kB)\n",
            "\u001b[K     |████████████████████████████████| 419kB 43.4MB/s \n",
            "\u001b[?25hCollecting google-pasta>=0.1.2 (from tensorflow-gpu==2.0.0-alpha0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/68/a14620bfb042691f532dcde8576ff82ee82e4c003cdc0a3dbee5f289cee6/google_pasta-0.1.6-py3-none-any.whl (51kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 27.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==2.0.0-alpha0) (41.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==2.0.0-alpha0) (2.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0-alpha0) (0.15.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0-alpha0) (3.1.1)\n",
            "Installing collected packages: tb-nightly, tf-estimator-nightly, google-pasta, tensorflow-gpu\n",
            "Successfully installed google-pasta-0.1.6 tb-nightly-1.14.0a20190301 tensorflow-gpu-2.0.0a0 tf-estimator-nightly-1.14.0.dev2019030115\n",
            "2.0.0-alpha0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LqJRKR1ipca",
        "colab_type": "text"
      },
      "source": [
        "## 데이터 다운로드 및 데이터 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJOjJHfciukT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "c932c2c6-b9a9-4f1f-a201-618a3f62d5c2"
      },
      "source": [
        "# bugs music 에서 다운로드한 11,000 여곡의 한국 힙합 노래 가사 데이터를 불러옵니다.\n",
        "# 이 데이터는 연구용으로 제작되었으며 무단 전재 및 재배포를 금합니다.\n",
        "path_to_file = tf.keras.utils.get_file('input.txt', 'https://raw.githubusercontent.com/greentec/greentec.github.io/master/public/other/data/koreanhiphop/input.txt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://raw.githubusercontent.com/greentec/greentec.github.io/master/public/other/data/koreanhiphop/input.txt\n",
            "22921216/22919747 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiRqgiBTZ_1w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "34979f14-6566-43b4-b476-972515e81bc7"
      },
      "source": [
        "# 데이터를 불러옵니다. encoding 형식으로 utf-8 을 지정해야합니다.\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "# 빠른 테스트를 위해 데이터 크기를 1/5 로 줄이는 옵션입니다. \n",
        "# 더 큰 크기로 테스트하면 더 좋은 결과가 나오겠지만 epoch 당 학습 시간이 많이 필요합니다.\n",
        "# text = text[:len(text)//5]\n",
        "# 텍스트가 총 몇 자인지 확인합니다.\n",
        "print ('Length of text: {} characters'.format(len(text)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text: 11685293 characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTen2KG0aQop",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "672dffbf-15de-4691-e9a7-0ba72be3083c"
      },
      "source": [
        "# 처음 500 자를 확인해봅니다.\n",
        "print(text[:500])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pass me the ball cuz I make it 100\n",
            "I know ya ain't got no d\n",
            "Ain't nobody can stop me\n",
            "From scoring scoring (swish)\n",
            "Want more and more (swish)\n",
            "The more I hear that sound the hotter\n",
            "I get and you know it\n",
            "81 in one game\n",
            "너넨 못해 이런거\n",
            "I'm just sayin you know\n",
            "상처받았다면 I'm sorry\n",
            "I'm black mamba that's all\n",
            "Killer instinct man that's all\n",
            "너네가 못하는게 아냐\n",
            "I'm just better than y'all\n",
            "Fast like bugatti\n",
            "I get my shot in all the time\n",
            "I do never doubt it\n",
            "누가 붙든 간에 I know you can't stop me\n",
            "So either quintuple team me or jus\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49G7ztVtckcI",
        "colab_type": "text"
      },
      "source": [
        "## jamotools 설치 및 테스트"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oe_E6xgEag3Q",
        "colab_type": "text"
      },
      "source": [
        "한글은 초성, 중성, 종성으로 구성되어 있기 때문에 각 글자를 자모로 분할하여 데이터로 넣는 것이 분할하지 않는 것보다 메모리 관리 측면에서 훨씬 효율적입니다. \n",
        "\n",
        "아래 셀에서는 자모 분할, 합치기 작업을 도와주는 [jamotools](<https://github.com/HaebinShin/jamotools>) 라는 라이브러리를 설치합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXNSHMUNaaeo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "4efa8230-6204-4b17-af1a-5d2cab2a0e78"
      },
      "source": [
        "# jamotools 를 설치합니다.\n",
        "!pip install jamotools"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting jamotools\n",
            "  Downloading https://files.pythonhosted.org/packages/3d/d6/ec13c68f7ea6a8085966390d256d183bf8488f8b9770028359acb86df643/jamotools-0.1.10-py2.py3-none-any.whl\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from jamotools) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from jamotools) (1.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from jamotools) (1.16.3)\n",
            "Installing collected packages: jamotools\n",
            "Successfully installed jamotools-0.1.10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pcyUS_na6zp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "3d2d10c5-7adf-4c6e-90e6-9960ee0a504d"
      },
      "source": [
        "# jamotools 를 사용하기 위해 import 합니다.\n",
        "import jamotools\n",
        "# 한글과 영어가 같이 있는 부분을 임의로 발췌했습니다.\n",
        "s = text[3008:3092]\n",
        "print(s)\n",
        "print()\n",
        "# 한글 텍스트를 자모 단위로 분리해줍니다. 영어에는 영향이 없습니다.\n",
        "s_split = jamotools.split_syllables(s)\n",
        "print(s_split)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "니 생각을 매일해\n",
            "Hot news처럼 걸렸어\n",
            "내 life의 메인에\n",
            "실검 1위 맨 위에\n",
            "널 찾아 해메이네\n",
            "아예 추가해놨어\n",
            "내 즐겨찾기 page에 yeah\n",
            "\n",
            "ㄴㅣ ㅅㅐㅇㄱㅏㄱㅇㅡㄹ ㅁㅐㅇㅣㄹㅎㅐ\n",
            "Hot newsㅊㅓㄹㅓㅁ ㄱㅓㄹㄹㅕㅆㅇㅓ\n",
            "ㄴㅐ lifeㅇㅢ ㅁㅔㅇㅣㄴㅇㅔ\n",
            "ㅅㅣㄹㄱㅓㅁ 1ㅇㅟ ㅁㅐㄴ ㅇㅟㅇㅔ\n",
            "ㄴㅓㄹ ㅊㅏㅈㅇㅏ ㅎㅐㅁㅔㅇㅣㄴㅔ\n",
            "ㅇㅏㅇㅖ ㅊㅜㄱㅏㅎㅐㄴㅘㅆㅇㅓ\n",
            "ㄴㅐ ㅈㅡㄹㄱㅕㅊㅏㅈㄱㅣ pageㅇㅔ yeah\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KroeX9pycIrI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "bfd88df9-4065-4215-b4ee-334061e520c8"
      },
      "source": [
        "# jamotools 에서 분리했던 자모를 다시 합치는 기능을 테스트해봅니다.\n",
        "s2 = jamotools.join_jamos(s_split)\n",
        "print(s2)\n",
        "print(s == s2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "니 생각을 매일해\n",
            "Hot news처럼 걸렸어\n",
            "내 life의 메인에\n",
            "실검 1위 맨 위에\n",
            "널 찾아 해메이네\n",
            "아예 추가해놨어\n",
            "내 즐겨찾기 page에 yeah\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aSEEpYlc0JC",
        "colab_type": "text"
      },
      "source": [
        "## 텍스트 전처리\n",
        "\n",
        "jamotool 를 활용해서 korean hiphop 데이터를 자모 단위로 나누고, RNN 학습에 적합하도록 전처리하는 과정입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiaQx08rc9Sh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0ad2d9de-f726-4fec-c32f-d1d444d18f83"
      },
      "source": [
        "# 텍스트를 자모 단위로 나눕니다. 데이터가 크기 때문에 약간 시간이 걸립니다.\n",
        "text_jamo = jamotools.split_syllables(text)\n",
        "# 자모 단위 텍스트에 존재하는 unique character 를 set 을 이용해서 뽑아내고, sorted 로 정렬합니다.\n",
        "# 이 unique charater 를 보통 vocabulary 라고 합니다.\n",
        "vocab = sorted(set(text_jamo))\n",
        "print ('{} unique characters'.format(len(vocab)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1108 unique characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3UB5jOAeMXI",
        "colab_type": "text"
      },
      "source": [
        "텍스트를 RNN 에 입력하기 위해서는 숫자로 mapping 해야 합니다. \n",
        "\n",
        "character 를 number 로 맵핑해서 input data 를 만들고, number 를 character 로 맵핑하는 데이터를 만들어서 output data 를 해석합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJe5nu03dbSB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# vocab character 를 숫자로 맵핑하고, 반대도 실행합니다.\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "text_as_int = np.array([char2idx[c] for c in text_jamo])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YF_7WtBafMYq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "outputId": "8f2c8f68-22b3-4d8d-b468-fd5fd7374e4d"
      },
      "source": [
        "# char2idx 의 일부를 알아보기 쉽게 print 해봅니다.\n",
        "print('{')\n",
        "for char,_ in zip(char2idx, range(20)):\n",
        "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))\n",
        "print('  ...\\n}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  '\\n':   0,\n",
            "  ' ' :   1,\n",
            "  '!' :   2,\n",
            "  '\"' :   3,\n",
            "  '#' :   4,\n",
            "  '$' :   5,\n",
            "  '%' :   6,\n",
            "  '&' :   7,\n",
            "  \"'\" :   8,\n",
            "  '(' :   9,\n",
            "  ')' :  10,\n",
            "  '*' :  11,\n",
            "  '+' :  12,\n",
            "  ',' :  13,\n",
            "  '-' :  14,\n",
            "  '.' :  15,\n",
            "  '/' :  16,\n",
            "  '0' :  17,\n",
            "  '1' :  18,\n",
            "  '2' :  19,\n",
            "  ...\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OI1ZMBN1fRZ4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "98b64714-d7b7-4059-b142-794e694aa845"
      },
      "source": [
        "# 자모 단위 텍스트의 숫자로 잘 맵핑되었는지 확인해봅니다.\n",
        "print ('{} ---- characters mapped to int ---- > {}'.format(repr(text_jamo[210:233]), text_as_int[210:233]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "' game\\nㄴㅓㄴㅔㄴ ㅁㅗㅅㅎㅐ ㅇㅣㄹㅓㄴ' ---- characters mapped to int ---- > [  1  72  66  78  70   0 354 385 354 386 354   1 367 389 371 380 382   1\n",
            " 373 401 359 385 354]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0ePgF5QhU2A",
        "colab_type": "text"
      },
      "source": [
        "## Dataset 만들기\n",
        "\n",
        "딥러닝 학습을 위해서 batch 단위로 묶인 dataset 을 만들어야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQyiXMU3ivCC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "10609c7e-41d5-4012-9451-23218515e4e1"
      },
      "source": [
        "# The maximum length sentence we want for a single input in characters\n",
        "seq_length = 100\n",
        "examples_per_epoch = len(text_jamo)//seq_length\n",
        "\n",
        "# Create training examples / targets\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "\n",
        "for i in char_dataset.take(5):\n",
        "  print(idx2char[i.numpy()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "P\n",
            "a\n",
            "s\n",
            "s\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGVTLNKlg2fp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "cace97cf-bfef-4ffe-e2d7-ecb67c27dfb3"
      },
      "source": [
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for item in sequences.take(5):\n",
        "  print(repr(''.join(idx2char[item.numpy()])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\"Pass me the ball cuz I make it 100\\nI know ya ain't got no d\\nAin't nobody can stop me\\nFrom scoring sco\"\n",
            "'ring (swish)\\nWant more and more (swish)\\nThe more I hear that sound the hotter\\nI get and you know it\\n8'\n",
            "\"1 in one game\\nㄴㅓㄴㅔㄴ ㅁㅗㅅㅎㅐ ㅇㅣㄹㅓㄴㄱㅓ\\nI'm just sayin you know\\nㅅㅏㅇㅊㅓㅂㅏㄷㅇㅏㅆㄷㅏㅁㅕㄴ I'm sorry\\nI'm black mamba \"\n",
            "\"that's all\\nKiller instinct man that's all\\nㄴㅓㄴㅔㄱㅏ ㅁㅗㅅㅎㅏㄴㅡㄴㄱㅔ ㅇㅏㄴㅑ\\nI'm just better than y'all\\nFast like\"\n",
            "\" bugatti\\nI get my shot in all the time\\nI do never doubt it\\nㄴㅜㄱㅏ ㅂㅜㅌㄷㅡㄴ ㄱㅏㄴㅇㅔ I know you can't stop me\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1-pkVfHg8XR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqp5p5yEhEJR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "18e473c2-313d-4f5e-d097-ea6fc4081861"
      },
      "source": [
        "for input_example, target_example in  dataset.take(1):\n",
        "  print ('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
        "  print ('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input data:  \"Pass me the ball cuz I make it 100\\nI know ya ain't got no d\\nAin't nobody can stop me\\nFrom scoring sc\"\n",
            "Target data: \"ass me the ball cuz I make it 100\\nI know ya ain't got no d\\nAin't nobody can stop me\\nFrom scoring sco\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Kx2X-SNhF2x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "187f70b8-9a9d-4c53-b9db-4e6ed59c23a1"
      },
      "source": [
        "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
        "    print(\"Step {:4d}\".format(i))\n",
        "    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
        "    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step    0\n",
            "  input: 49 ('P')\n",
            "  expected output: 66 ('a')\n",
            "Step    1\n",
            "  input: 66 ('a')\n",
            "  expected output: 84 ('s')\n",
            "Step    2\n",
            "  input: 84 ('s')\n",
            "  expected output: 84 ('s')\n",
            "Step    3\n",
            "  input: 84 ('s')\n",
            "  expected output: 1 (' ')\n",
            "Step    4\n",
            "  input: 1 (' ')\n",
            "  expected output: 78 ('m')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8UV2Ig7hMKx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "d2c78ea9-24c8-4aa4-9c4d-ebb0ec31bfff"
      },
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = examples_per_epoch//BATCH_SIZE\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wx9_mba3isCi",
        "colab_type": "text"
      },
      "source": [
        "## tf.keras 를 이용한 딥러닝 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-ieAWgch2Zz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Length of the vocabulary in chars\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juDnRk18h6LR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "4779d8bb-675f-4efc-ff4a-b1039adc2299"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(len(vocab), embedding_dim,\n",
        "                              batch_input_shape=[BATCH_SIZE, None]),\n",
        "    tf.keras.layers.GRU(rnn_units,\n",
        "        return_sequences=True,\n",
        "        recurrent_initializer='glorot_uniform',\n",
        "        stateful=True),\n",
        "    tf.keras.layers.Dense(vocab_size)\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (64, None, 256)           283648    \n",
            "_________________________________________________________________\n",
            "unified_gru (UnifiedGRU)     (64, None, 1024)          3938304   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (64, None, 1108)          1135700   \n",
            "=================================================================\n",
            "Total params: 5,357,652\n",
            "Trainable params: 5,357,652\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjG0ZOgJiDIy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8dc805c3-a70a-481f-c98c-fa07252ed7ca"
      },
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "  example_batch_predictions = model(input_example_batch)\n",
        "  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 100, 1108) # (batch_size, sequence_length, vocab_size)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6GjDj5Qkke6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xthtrpKkmG5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(\n",
        "    optimizer = tf.optimizers.Adam(),\n",
        "    loss = loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srO1xh7KkpUR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "# 모델의 체크포인트가 저장될 디렉토리 이름입니다.\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "\n",
        "# 체크포인트 파일은 아래에서 지정하는 ckpt_{epoch} 형태로 접두사를 달게 됩니다. 즉 ckpt_5, ckpt_10, ... 이 됩니다.\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "# 체크포인트 콜백은 model.fit 을 실행할 때 호출됩니다. period 는 저장 주기입니다.\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True,\n",
        "    period=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOtP5-WhkwRI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeoZQvpsktoQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 737
        },
        "outputId": "73a874cb-3c50-4c1c-a3b0-1d4995414344"
      },
      "source": [
        "# 모델을 실제로 학습시킵니다.\n",
        "# 진행 막대를 표시하지 않기 위해서 verbose=2 로 설정합니다. (0 = 표시없음, 1 = 진행막대 표시)\n",
        "history = model.fit(dataset.repeat(), epochs=EPOCHS, steps_per_epoch=steps_per_epoch, callbacks=[checkpoint_callback], verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "3078/3078 - 223s - loss: 1.6251\n",
            "Epoch 2/20\n",
            "3078/3078 - 221s - loss: 1.4974\n",
            "Epoch 3/20\n",
            "3078/3078 - 221s - loss: 1.4577\n",
            "Epoch 4/20\n",
            "3078/3078 - 221s - loss: 1.4388\n",
            "Epoch 5/20\n",
            "3078/3078 - 221s - loss: 1.4300\n",
            "Epoch 6/20\n",
            "3078/3078 - 221s - loss: 1.4262\n",
            "Epoch 7/20\n",
            "3078/3078 - 221s - loss: 1.4265\n",
            "Epoch 8/20\n",
            "3078/3078 - 221s - loss: 1.4298\n",
            "Epoch 9/20\n",
            "3078/3078 - 221s - loss: 1.4388\n",
            "Epoch 10/20\n",
            "3078/3078 - 221s - loss: 1.4567\n",
            "Epoch 11/20\n",
            "3078/3078 - 220s - loss: 2.0399\n",
            "Epoch 12/20\n",
            "3078/3078 - 221s - loss: 2.0144\n",
            "Epoch 13/20\n",
            "3078/3078 - 220s - loss: 1.9211\n",
            "Epoch 14/20\n",
            "3078/3078 - 220s - loss: 1.7866\n",
            "Epoch 15/20\n",
            "3078/3078 - 220s - loss: 1.6841\n",
            "Epoch 16/20\n",
            "3078/3078 - 220s - loss: 1.6283\n",
            "Epoch 17/20\n",
            "3078/3078 - 220s - loss: 1.5924\n",
            "Epoch 18/20\n",
            "3078/3078 - 220s - loss: 1.5706\n",
            "Epoch 19/20\n",
            "3078/3078 - 220s - loss: 1.5581\n",
            "Epoch 20/20\n",
            "3078/3078 - 220s - loss: 1.5575\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6GlRXAXFDTR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "a03b6683-c77e-483e-d36c-356673ee4da5"
      },
      "source": [
        "# 학습 결과 시각화를 위해 matplotlib.pyplot 모듈을 plt 라는 이름으로 축약해서 import 합니다.\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 위에서 history 라는 이름으로 저장했던 변수에 있는 loss 정보를 꺾은선 그래프로 그립니다.\n",
        "plt.plot(history.history['loss'])\n",
        "\n",
        "# plt.show() 함수를 호출해야 위에서 그린 그래프가 출력에 나타납니다.\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IPB-NMJpWW7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "50c8fceb-3779-41ac-a39f-f11c7513481f"
      },
      "source": [
        "# 가장 최신의 체크포인트 파일 이름을 출력합니다.\n",
        "tf.train.latest_checkpoint(checkpoint_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./training_checkpoints/ckpt_20'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDkuAFaKpZZq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "88e8124f-623a-462e-8b0a-b8f71757a974"
      },
      "source": [
        "# 텍스트 생성을 위해서 위와 네트워크 구조가 동일하지만 batch_size 가 1인 모델을 만듭니다. \n",
        "gen_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(len(vocab), embedding_dim,\n",
        "                              batch_input_shape=[1, None]),\n",
        "    tf.keras.layers.GRU(rnn_units,\n",
        "        return_sequences=True,\n",
        "        recurrent_initializer='glorot_uniform',\n",
        "        stateful=True),\n",
        "    tf.keras.layers.Dense(vocab_size)\n",
        "])\n",
        "\n",
        "# 최신의 체크포인트에서 weights 를 불러옵니다.\n",
        "gen_model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "\n",
        "# 가장 loss 가 낮은 weights 를 불러옵니다.\n",
        "min_loss = min(history.history['loss'])\n",
        "index = history.history['loss'].index(min_loss)\n",
        "print(min_loss, index)\n",
        "gen_model.load_weights('./training_checkpoints/ckpt_' + str(index+1))\n",
        "\n",
        "# build() 함수로 모델을 사용할 수 있도록 만듭니다. build() 함수를 사용할 때는 인수로 input_shape 을 같이 써줘야 합니다.\n",
        "gen_model.build(tf.TensorShape([1, None]))\n",
        "\n",
        "# gen_model의 구조를 출력합니다.\n",
        "gen_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.4262497359626551 5\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (1, None, 256)            283648    \n",
            "_________________________________________________________________\n",
            "unified_gru_1 (UnifiedGRU)   (1, None, 1024)           3938304   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (1, None, 1108)           1135700   \n",
            "=================================================================\n",
            "Total params: 5,357,652\n",
            "Trainable params: 5,357,652\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGTUMWc6pldR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_text(model, start_string):\n",
        "  # Evaluation step (generating text using the learned model)\n",
        "\n",
        "  # Number of characters to generate\n",
        "  num_generate = 1000\n",
        "\n",
        "  # Converting our start string to numbers (vectorizing)\n",
        "  input_eval = [char2idx[s] for s in start_string]\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "  # Empty string to store our results\n",
        "  text_generated_jamo = []\n",
        "\n",
        "  # Low temperatures results in more predictable text.\n",
        "  # Higher temperatures results in more surprising text.\n",
        "  # Experiment to find the best setting.\n",
        "  temperature = 1.0\n",
        "\n",
        "  # Here batch size == 1\n",
        "  model.reset_states()\n",
        "  for i in range(num_generate):\n",
        "      predictions = model(input_eval)\n",
        "      # remove the batch dimension\n",
        "      predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "      # using a multinomial distribution to predict the word returned by the model\n",
        "      predictions = predictions / temperature\n",
        "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "      # We pass the predicted word as the next input to the model\n",
        "      # along with the previous hidden state\n",
        "      input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "      text_generated_jamo.append(idx2char[predicted_id])\n",
        "      \n",
        "  text_generated = jamotools.join_jamos(''.join(text_generated_jamo))\n",
        "\n",
        "  return (jamotools.join_jamos(start_string) + text_generated)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfsuKbLBpnYZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "outputId": "67fa97a8-6d2b-4812-b811-66451a4a5abc"
      },
      "source": [
        "# print(generate_text(gen_model, start_string=u\"ㄴㅐㄱㅏ ㅈㅔㅇㅣㄹ \"))\n",
        "print(generate_text(gen_model, start_string=u\"ㅈㅏㅁㅇㅡㄴ ㅇㅏㄴㅇㅗㄱㅗ \"))\n",
        "# print(generate_text(gen_model, start_string=u\"ㅇㅗㄴㅡㄹ ㅂㅏㅁㅇㅡㄴ \"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "잠은 안오고 선수들은 교폼\n",
            "먼지 위에 있니 추억이 날 위해 이 순간이\n",
            "생명은 그리워 가고 있는 이게 yee\n",
            "마시라'MMIN STILK AY 이미 간고식 \n",
            "배기 부는 이유 \n",
            "From 콘콜 통화 매번 날아가\n",
            "teken is better than the perfect\n",
            "to my tody 최면에 입고 앉아 with ya 보이니까 모두 boss by 휘과저 회계\n",
            "너넨 빨감한 위치\n",
            "뭔가 변해\n",
            "니 번째로 행복한 일상\n",
            "난 잘 알고 있을 줄과 복\n",
            "어릴 때 몇 년 쪽\n",
            "음악 그 속에 뒤토를 지세상으로 하나없어 술도 \n",
            "산이 될 못 참고 인기는 사랑해 오늘은 hey\n",
            "너는\n",
            "hit me ur new if piece\n",
            "Lookin so baur 녹아\n",
            "133 느껴봐 나는 도착 온 되는 자존감옷\n",
            "유사 받아있던 우리 인생은 krayou\n",
            "가로주를 모르는 인생\n",
            "\n",
            "fan-nation ask with a supacconts\n",
            "얼리너 약간 한 것만 같애 \n",
            "이제꺼고플 빨리 가서내려\n",
            "가뭄에 올라가게 뛰나봐\n",
            "신이 되기 많아 잠마 있어 최로운 걸)\n",
            "\n",
            "어쩌면 그래 우리 사이는 안 보이는 체대로 색깔\n",
            "돈을 쫌 건드려 누가 신경섬 없이 빡빡주의 바다로\n",
            "이미 끝까지 휩을 떠올려줘\n",
            "그도 난 너를 사렁알자 빠지\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}